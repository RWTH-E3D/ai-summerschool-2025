{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c75c2-2083-4128-b140-a38c3f401370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler, no One Hot input vectors, no Sigmoid, BCELossWithLogitsLoss (with weight), Cross Validation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "torch.manual_seed(42) # Reproduzierbarkeit des Shuffles im DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91407dd6-4c8e-4dd4-b599-b29d5f4cfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load tha data Goal: Load the dataset from a CSV and extract features and labels.\n",
    "\n",
    "data_path = r\"/home/ubuntu/Desktop/Übergabe Masterarbeit Julius/Daten/291024/Daten291024.csv\"\n",
    "\n",
    "data = pd.read_csv(data_path, sep=';', decimal=',')\n",
    "# Extract labels and features\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    "\n",
    "# Separation into single values and time series (3 single values + 15 sequence values)\n",
    "static_features = X[:, [0, 1, 7]]        # max_force, avg_force, avg_speed\n",
    "force_seq = X[:, 2:7]                    # Columns 4-8 (Force)\n",
    "speed_seq = X[:, 8:13]                   # Columns 10-14 (Speed)\n",
    "dist_seq = X[:, 13:18]                   # Columns 15-19 (Distance)\n",
    "sequence_features = np.stack([force_seq, speed_seq, dist_seq], axis=1)  # → (Samples, 3, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae19df-1b70-46a5-a014-cb0bddf39e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CNN Model Define a 1D CNN model in PyTorch that processes both sequential and static input data.\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, ceil_mode=True)\n",
    "        self.fc1 = nn.Linear(16 * 3 + 3, 64)  # +3 because of the static features\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_seq, x_static):\n",
    "        x = torch.relu(self.conv1(x_seq))   # (B, 16, 5)\n",
    "        x = self.pool(x)                    # (B, 16, 2)\n",
    "        x = x.view(x.size(0), -1)           # (B, 48)\n",
    "        x = torch.cat((x, x_static), dim=1) # (B, 51)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e813a-da7d-4be4-93c9-d769c9b6c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Cross-Validation Setup Set up 5-fold stratified cross-validation and initialize result containers.\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "all_test_probabilities = []\n",
    "misclassified_samples = []\n",
    "total_conf_matrix = np.zeros((2, 2))\n",
    "all_training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f29375-deed-44b6-8401-80fdb635b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  4. Fold Loop - Training and Evaluation Goal: For each fold, preprocess, train, and evaluate.\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "\n",
    "    # Create training and test sets for this fold\n",
    "    X_train_seq, X_test_seq = sequence_features[train_idx], sequence_features[test_idx]\n",
    "    X_train_static, X_test_static = static_features[train_idx], static_features[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Normalization per channel separately\n",
    "    X_train_seq_flat = X_train_seq.reshape(X_train_seq.shape[0], -1)\n",
    "    X_test_seq_flat = X_test_seq.reshape(X_test_seq.shape[0], -1)\n",
    "\n",
    "    scaler_seq = MinMaxScaler()\n",
    "    X_train_seq_flat = scaler_seq.fit_transform(X_train_seq_flat)\n",
    "    X_test_seq_flat = scaler_seq.transform(X_test_seq_flat)\n",
    "    X_train_seq = X_train_seq_flat.reshape(-1, 3, 5)\n",
    "    X_test_seq = X_test_seq_flat.reshape(-1, 3, 5)\n",
    "\n",
    "    scaler_static = MinMaxScaler()\n",
    "    X_train_static = scaler_static.fit_transform(X_train_static)\n",
    "    X_test_static = scaler_static.transform(X_test_static)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_seq = torch.tensor(X_train_seq, dtype=torch.float32)\n",
    "    X_test_seq = torch.tensor(X_test_seq, dtype=torch.float32)\n",
    "    X_train_static = torch.tensor(X_train_static, dtype=torch.float32)\n",
    "    X_test_static = torch.tensor(X_test_static, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    # Creation of the TensorDataset and DataLoader for training\n",
    "    train_dataset = TensorDataset(X_train_seq, X_train_static, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=40, shuffle=True)\n",
    "\n",
    "    # Calculation of class weights\n",
    "    class_counts = torch.tensor([(y_train == 0).sum(), (y_train == 1).sum()], dtype=torch.float32)\n",
    "    pos_weight = class_counts[0] / class_counts[1]\n",
    "\n",
    "    # Initialize the model\n",
    "    model = CNNModel()\n",
    "\n",
    "    # Training configuration\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training the model\n",
    "    epochs = 100\n",
    "    training_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_seq_batch, X_static_batch, y_batch in train_loader:\n",
    "            outputs = model(X_seq_batch, X_static_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        training_losses.append(epoch_loss / len(train_loader))\n",
    "\n",
    "    all_training_losses.append(training_losses)\n",
    "\n",
    "    # Test run and collect metrics\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_seq, X_test_static)\n",
    "        test_probs = torch.sigmoid(test_outputs)\n",
    "        test_pred = (test_probs >= 0.5).float()\n",
    "        test_loss = criterion(test_outputs, y_test).item()\n",
    "        test_losses.append(test_loss)\n",
    "        conf_matrix = confusion_matrix(y_test.numpy(), test_pred.numpy())\n",
    "\n",
    "    total_conf_matrix += conf_matrix\n",
    "\n",
    "    all_test_probabilities.extend(zip(test_idx, test_probs.numpy()))\n",
    "\n",
    "    # Save misclassified samples\n",
    "    for i, (true_label, predicted_label) in enumerate(zip(y_test.numpy(), test_pred.numpy())):\n",
    "        if true_label != predicted_label:\n",
    "            misclassified_samples.append({\n",
    "                'Index': int(test_idx[i])+1,\n",
    "                'True Label': int(true_label),\n",
    "                'Predicted Label': int(predicted_label),\n",
    "                'Error Type': 'FP' if predicted_label == 1 else 'FN'\n",
    "            })\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "total_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9ac10-97d2-45ee-8ac4-6d8da7f559b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Post-Processing and Results Goal: Summarize results and visualize outcomes.\n",
    "# Bring results back into the original order\n",
    "all_test_probabilities.sort(key=lambda x: x[0])  # Sort by original index\n",
    "sorted_probabilities = [prob for _, prob in all_test_probabilities] # Extract probabilities\n",
    "\n",
    "\n",
    "# Output the probabilities\n",
    "print(\"Vorhergesagte Wahrscheinlichkeiten in der Originalreihenfolge:\")\n",
    "for i, prob in enumerate(sorted_probabilities, start=1):\n",
    "    print(f\"Sample {i}: {prob:.4f}\")\n",
    "\n",
    "# Output misclassified samples\n",
    "print(\"Falsch klassifizierte Samples:\")\n",
    "for sample in misclassified_samples:\n",
    "    print(f\"Index: {sample['Index']}, True Label: {sample['True Label']}, Predicted Label: {sample['Predicted Label']}, Error Type: {sample['Error Type']}\")\n",
    "\n",
    "# Output overall results\n",
    "TP = total_conf_matrix[1, 1]\n",
    "TN = total_conf_matrix[0, 0]\n",
    "FP = total_conf_matrix[0, 1]\n",
    "FN = total_conf_matrix[1, 0]\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "avg_test_loss = np.mean(test_losses)\n",
    "\n",
    "print(f'Gesamtergebnis: Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, Test Loss: {avg_test_loss:.4f}, Zeit: {total_time:.4f}')\n",
    "\n",
    "# Plot overall confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(total_conf_matrix[[1, 0]][:, [1, 0]].astype(int), annot=True, fmt='d', cmap='Blues', xticklabels=['Positive', 'Negative'], yticklabels=['Positive', 'Negative'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Overall Confusion Matrix across all folds')\n",
    "plt.show()\n",
    "\n",
    "# Plot training losses across all folds\n",
    "plt.figure(figsize=(10, 6))\n",
    "for fold, losses in enumerate(all_training_losses):\n",
    "    plt.plot(range(1, epochs + 1), losses, label=f'Fold {fold + 1}')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss über alle Folds\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
