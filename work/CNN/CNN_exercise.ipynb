{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1f8d3-27de-4b63-bab4-cf27a1a80af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.classification import MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4e5fc-5a09-4a35-8143-9e27a3557daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link for nn and all the other functions, api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552a8dc-7c94-4fc0-8e5c-3fa44bc089e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Give directions to the path of the data set using data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d244a-fff1-4097-92d9-93c402f79ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 includes transforming PNG data into numbers, so the data is ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bd7946-02ef-4286-9927-7b18c03bfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 To transform the input images all of the substeps for step 2 need to composed into a list, use \"transform\"\n",
    "# 2.2 CNN inputs need to be the same size, therefore resize the input image to 128×128 pixels.\n",
    "# 2.3 Convert a PIL image (or NumPy array) into a PyTorch tensor.\n",
    "# 2.4 Normalize the pixel values using the formula normalized value=(value−mean)/std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04166136-3182-4779-9faf-6590d11fcaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Step 3 is now to apply the transformed pipeline to each image in the folders, use datasets.ImageFolder()\n",
    "# 3.2. Now the dataset is to be wrapped in a DataLoader by sending in the data in batches of 4, shuffling the order of the data to make the training faster and more reliable\n",
    "# use DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833138c1-de94-4f82-93ab-d5668071ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 is building the actual CNN - the brain of the model\n",
    "# 4.1 Define the class, use class \"Name of the Model\"(nnModule)\n",
    "# 4.2 Set up the layers of the model using __init__ and use super(...) to make sure that PyTorch's internal stuff works properly\n",
    "# 4.3 Create Convoltional Layers following these steps:\n",
    "# 1. First layer turns 3-channel input (RGB image) into 16 feature maps, use nn.Conv2d()\n",
    "# 2. Use ReLU to add non-linearity (so it can learn more than just straight lines)\n",
    "# 3. Use MaxPool to downsize the feature maps (to reduce computation and focus on key features).\n",
    "# 4. Then another conv layer, now from 16 ➡ 32 channels.\n",
    "# 4.4 Make Fully Connected Layers\n",
    "# 1. Use flatten to turn 3D data into 1D so it can go into linear layers\n",
    "# 2. Use Linear to compress the data to 128 neurons\n",
    "# 3. Use Linear one more time to map however many classes are being predicted\n",
    "# 4.5 Use Forward pass to create a flow of data through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b366c47-643f-4d49-800b-e9be217f5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Write a code to choose either CPU or GPU using torch.device\n",
    "# 5.2 Create the model and send it to the device\n",
    "# 5.3 Define the Loss Function (how many mistakes is the model making?) using criterion\n",
    "# 5.4 Choose an Optimizer to update the model's parametrs to reduce the loss, use optimizer = optim.\"a type of optmizer\"(model.parameters, lr=...), lr being the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092641e0-2881-471a-ae7b-69f499dd3ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 6th step os to create a training loop\n",
    "# 6.1 Loop over the dataset 5 times. Each full loop = 1 epoch (1 full pass over the dataset).\n",
    "# 6.2 Put the model into “training mode.”\n",
    "# 6.3 Track the Running Loss\n",
    "# 6.4 Loop Over the Data, get a batch of images (inputs) and their true labels (labels).\n",
    "# 6.5 Move Data to Device, send both data and labels to the GPU or CPU.\n",
    "# 6.6 Clear Previous Gradients so that they don't stack up and mess up the learning, use optimizer\n",
    "# 6.7 Pass the input images through the model to get predictions, use outputs = model(...)\n",
    "# 6.8  Calculate Loss by comparing the predictions to the correct labels using the loss function, use loss = criterion(...)\n",
    "# 6.9 Do backpropagation — it figures out how to change the model’s weights based on the error.\n",
    "# 6.10  Now use those calculated changes to update the model's weights. This is where learning happens. Use the optimizer once more.\n",
    "# 6.11 Keep Track of Loss, use loss.item()\n",
    "# 6.12 Print Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc5ccb-fc14-455a-89fd-9c46f581b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7th step is to visualize predictions\n",
    "# 7.1 Switch the model to “evaluation mode.”\n",
    "# 7.2 Turn Off Gradient Calculations, because the gradients are only needed for training, not predicting\n",
    "# 7.3 Grab a Small Batch of Data as a smaple to visualize\n",
    "# 7.4 Move the images to the same device the model is on - GPU or CPU.\n",
    "# 7.5 Make Predictions - Feed the images into the model\n",
    "# 7.6 Get the Most Likely Class - find from the output scores the index of the highest value for each image\n",
    "# 7.7 Prepare for Plotting - Start a new matplotlib figure, and set its size (10 inches wide, 4 inches tall).\n",
    "# 7.8 Loop Through the First 4 Images\n",
    "# 7.9 Un-normalize and Convert Image to NumPy\n",
    "# 7.10 Plot Each Image\n",
    "# 7.11 Render the visualization in your notebook. Now you can see what the model thinks each image is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c980a3-2496-4d0b-968a-4af92926ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8th Step is to make a Confusion matrix Code\n",
    "# 8.1 import following libraries:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# 8.2 Switch the model to “evaluation mode.”\n",
    "# 8.3 Collect all the predicted and actual labels so we can compute the matrix after the loop using all_preds and all_labels\n",
    "\n",
    "# 8.4 Use torch.no_grad() to save memory\n",
    "# 8.5 Loop through batches in the dataloader.\n",
    "# 8.6 Move the input images and labels to the correct device (CPU/GPU) using inputs.to(device) and labels.to(device)\n",
    "# 8.7 Get the output predictions from the model.\n",
    "# 8.8 Use argmax to get the most likely class from the output probabilities.\n",
    "# 8.9 Convert predictions and labels to NumPy arrays and add them to the lists.\n",
    "\n",
    "# 8.10 Compute the confusion matrix with all_labels and all_preds as variables\n",
    "# 8.11 Use dataset.classes to retrieve the actual class names (like ['door', 'wall', 'window']) for labeling the axes.\n",
    "\n",
    "# 8.12 Now plot the matrix following these steps:\n",
    "# - Create a figure of a specific size using plt.figure(figsize=(6, 5)).\n",
    "# - Use sns.heatmap() in to draw the matrix using this line of code: sns.heatmap() with:\n",
    "# 1. annot=True to show the numbers.\n",
    "\n",
    "# 2. fmt='d' to format as integers.\n",
    "\n",
    "# 3. Use class names for tick labels.\n",
    "\n",
    "# Label the x-axis (“Predicted”) and y-axis (“Actual”) with plt.xlabel('Predicted').\n",
    "# Show the plot using plt.tight_layout() and plt.show()."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
